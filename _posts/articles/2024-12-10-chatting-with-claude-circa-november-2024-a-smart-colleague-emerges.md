---
category: articles
created: 2024-12-10 10:31:00
tags:
- ai
- llms
- research
- remote
title: Chatting with Claude circa November 2024 - A smart colleague emerges
---

I'm a remote worker, so I don't get to have many casual chats with my smart colleagues. Everyone has video call fatigue. Even a friendly catch-up, if it requires a calendar invite, feels forced and draining. It just doesn’t have the same atmosphere as spitballing on a whiteboard with the person across the hall.

Claude is getting good enough to fill some of this void.

In fact, even if I were in-person at JPL, there aren't many current coworkers who know enough about both JAX's automatic differentiation system and InSAR phase linking to have a coherent conversation. The fact that Claude can mimic a skilled tutor for me, giving just the context level that's out of my comfort zone to make me learn, is mind-blowing.

The catch: you have to already be an expert at talking to Claude to get the tutoring expertise out of its latent space. Code completion is a little easier, though plenty of people are finding that [expert programmers](https://arxiv.org/pdf/2401.15232) get more out of LLMs than novices.

But, one might argue that figuring out the right context to give, and the right keywords to use, applies equally to machines and to people. A skilled conversationalist knows you don't dive in too quickly - you give yourself and the other person time to figure out some common ground. For technical conversations, that can mean using broader terms and assuming less background knowledge. Then once you see that the person has all the prerequisites, you can jump to full-blown jargon.

Of course, that dance can be tiring to do all the time. Sometimes you want to jump straight to your question, as worded in your head, jargon and all. This is when being surrounded by similar students, or colleagues, can be most rewarding - you're all on the same page, taking the same class, and you can use jargon to cut right to the matter at hand.

I've started succeeding in leading Claude enough to be useful with my own research questions. Sometimes I get better answers than I do from asking colleagues.

It hasn't reached the utility of a small meeting with only people I feel are roughly at or above my level. That setting still drastically outperforms any other format of technical discussion, including sessions with Claude.

But Slack conversations can often be tiring. Humans are slow at typing. The ones who are more thoughtful about typing still need time to actually think. The ones (including me) who try to respond as quickly as possible during an active Slack conversation usually throw in typos, or malformed sentences, or ambiguous pronouns and misplaced modifiers... we just aren't as fast as the machines at sending out coherent thoughts anymore.

A private tutor's job is to be a little bit smarter than you while sensing the right level of content to lead you forward. People pay hundreds of dollars per week for a good tutor that can do this well; $240 for a year for Claude seems not so bad. We’re still so early in getting the user experience of LLMs correct, there are surely huge improvements coming within months once more developers see [the low-hanging fruit](https://x.com/karpathy/status/1866896395363553418).
